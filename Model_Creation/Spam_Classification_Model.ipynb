{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "_L47J5QQ2rJl"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "Z9GmbJbc2_3n"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('spam.csv', encoding='ISO-8859-1')\n",
        "\n",
        "df.drop([\"Unnamed: 2\", \"Unnamed: 3\", \"Unnamed: 4\"], axis=1, inplace=True)\n",
        "\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(df['v2'])\n",
        "word_index = tokenizer.word_index\n",
        "sequences = tokenizer.texts_to_sequences(df['v2'])\n",
        "padded_sequences = pad_sequences(sequences, maxlen=100, padding='post', truncating='post')\n",
        "\n",
        "labels = df['v1'].apply(lambda x: 1 if x == 'spam' else 0).values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "13b2POwo3EM8"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(padded_sequences, labels, test_size=0.25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "dqdoFcZZ3Tuq"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "    Embedding(len(word_index) + 1, 128, input_length=100),\n",
        "    LSTM(64),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "QdjqKv_83Yyo"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "131/131 [==============================] - 4s 29ms/step - loss: 0.4095 - accuracy: 0.8646 - val_loss: 0.3894 - val_accuracy: 0.8701\n",
            "Epoch 2/10\n",
            "131/131 [==============================] - 4s 29ms/step - loss: 0.3992 - accuracy: 0.8646 - val_loss: 0.3887 - val_accuracy: 0.8701\n",
            "Epoch 3/10\n",
            "131/131 [==============================] - 4s 29ms/step - loss: 0.3980 - accuracy: 0.8646 - val_loss: 0.3870 - val_accuracy: 0.8701\n",
            "Epoch 4/10\n",
            "131/131 [==============================] - 4s 29ms/step - loss: 0.3973 - accuracy: 0.8646 - val_loss: 0.3913 - val_accuracy: 0.8701\n",
            "Epoch 5/10\n",
            "131/131 [==============================] - 4s 30ms/step - loss: 0.3985 - accuracy: 0.8646 - val_loss: 0.3953 - val_accuracy: 0.8701\n",
            "Epoch 6/10\n",
            "131/131 [==============================] - 4s 28ms/step - loss: 0.3988 - accuracy: 0.8646 - val_loss: 0.3871 - val_accuracy: 0.8701\n",
            "Epoch 7/10\n",
            "131/131 [==============================] - 4s 29ms/step - loss: 0.3975 - accuracy: 0.8646 - val_loss: 0.3863 - val_accuracy: 0.8701\n",
            "Epoch 8/10\n",
            "131/131 [==============================] - 4s 28ms/step - loss: 0.3987 - accuracy: 0.8646 - val_loss: 0.3870 - val_accuracy: 0.8701\n",
            "Epoch 9/10\n",
            "131/131 [==============================] - 4s 28ms/step - loss: 0.3970 - accuracy: 0.8646 - val_loss: 0.3867 - val_accuracy: 0.8701\n",
            "Epoch 10/10\n",
            "131/131 [==============================] - 4s 28ms/step - loss: 0.3976 - accuracy: 0.8646 - val_loss: 0.3863 - val_accuracy: 0.8701\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x2c993be80>"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "-A62txja3Z8Z"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "44/44 [==============================] - 0s 7ms/step - loss: 0.3863 - accuracy: 0.8701\n",
            "Test accuracy: 0.8700646162033081\n"
          ]
        }
      ],
      "source": [
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print('Test accuracy:', accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-RQMh7H3l-G"
      },
      "source": [
        "# Change model type and package it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "3Xwl-_k63oj5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/achintya/Achintya/Competitions/Kochi/.venv/lib/python3.9/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "model.save('spam_ham_model.h5')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "xVzeW_hN3tQ5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /var/folders/k_/x2cc2f4901v6lyz_t7w3w3h40000gn/T/tmpol3qin1i/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /var/folders/k_/x2cc2f4901v6lyz_t7w3w3h40000gn/T/tmpol3qin1i/assets\n",
            "2024-02-03 15:43:57.103634: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:378] Ignored output_format.\n",
            "2024-02-03 15:43:57.103647: W tensorflow/compiler/mlir/lite/python/tf_tfl_flatbuffer_helpers.cc:381] Ignored drop_control_dependency.\n",
            "2024-02-03 15:43:57.103756: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: /var/folders/k_/x2cc2f4901v6lyz_t7w3w3h40000gn/T/tmpol3qin1i\n",
            "2024-02-03 15:43:57.106983: I tensorflow/cc/saved_model/reader.cc:51] Reading meta graph with tags { serve }\n",
            "2024-02-03 15:43:57.106988: I tensorflow/cc/saved_model/reader.cc:146] Reading SavedModel debug info (if present) from: /var/folders/k_/x2cc2f4901v6lyz_t7w3w3h40000gn/T/tmpol3qin1i\n",
            "2024-02-03 15:43:57.116952: I tensorflow/cc/saved_model/loader.cc:233] Restoring SavedModel bundle.\n",
            "2024-02-03 15:43:57.167429: I tensorflow/cc/saved_model/loader.cc:217] Running initialization op on SavedModel bundle at path: /var/folders/k_/x2cc2f4901v6lyz_t7w3w3h40000gn/T/tmpol3qin1i\n",
            "2024-02-03 15:43:57.193166: I tensorflow/cc/saved_model/loader.cc:316] SavedModel load for tags { serve }; Status: success: OK. Took 89410 microseconds.\n",
            "2024-02-03 15:43:57.286592: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
            "2024-02-03 15:43:57.286611: E tensorflow/compiler/mlir/lite/stablehlo/transforms/op_stat_pass.cc:119] Unsupported data type.\n",
            "Summary on the non-converted ops:\n",
            "---------------------------------\n",
            " * Accepted dialects: tfl, builtin, func\n",
            " * Non-Converted Ops: 25, Total Ops 66, % non-converted = 37.88 %\n",
            " * 22 ARITH ops, 3 TF ops\n",
            "\n",
            "- arith.constant:   22 occurrences  (f32: 8, i32: 14)\n",
            "\n",
            "  (i1: 1, i32: 1)\n",
            "\n",
            "\n",
            "- tf.TensorListReserve:    1 occurrences  (: 1)\n",
            "- tf.TensorListSetItem:    1 occurrences  (: 1)\n",
            "- tf.TensorListStack:    1 occurrences  (f32: 1)\n",
            "  (f32: 3, i32: 2)\n",
            "  (i32: 1)\n",
            "  (f32: 1)\n",
            "  (f32: 3)\n",
            "  (f32: 2)\n",
            "  (i1: 1)\n",
            "  (f32: 4)\n",
            "  (f32: 3)\n",
            "\n",
            "  (i32: 1)\n",
            "  (i32: 1)\n",
            "  (f32: 1)\n",
            "  (f32: 1, i32: 1)\n",
            "  (f32: 2)\n",
            "  (f32: 1)\n",
            "  (i32: 1)\n",
            "\n",
            "2024-02-03 15:43:57.289370: W tensorflow/compiler/mlir/lite/flatbuffer_export.cc:2921] TFLite interpreter needs to link Flex delegate in order to run the model since it contains the following Select TFop(s):\n",
            "Flex ops: FlexTensorListReserve, FlexTensorListSetItem, FlexTensorListStack\n",
            "Details:\n",
            "\ttf.TensorListReserve(tensor<2xi32>, tensor<i32>) -> (tensor<!tf_type.variant<tensor<?x64xf32>>>) : {device = \"\"}\n",
            "\ttf.TensorListSetItem(tensor<!tf_type.variant<tensor<?x64xf32>>>, tensor<i32>, tensor<?x64xf32>) -> (tensor<!tf_type.variant<tensor<?x64xf32>>>) : {device = \"\", resize_if_index_out_of_bounds = false}\n",
            "\ttf.TensorListStack(tensor<!tf_type.variant<tensor<?x64xf32>>>, tensor<2xi32>) -> (tensor<1x?x64xf32>) : {device = \"\", num_elements = 1 : i64}\n",
            "See instructions: https://www.tensorflow.org/lite/guide/ops_select\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "loaded_model = tf.keras.models.load_model('spam_ham_model.h5')\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(loaded_model)\n",
        "converter.experimental_enable_resource_variables = True\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "with open('model.tflite', 'wb') as f:\n",
        "    f.write(tflite_model)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
